{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 讀取資料\n",
    "情書大全: https://www.dgreetings.com/love_romance_cards/letters.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "Corpus = pd.read_excel(\"Love_letters.xlsx\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>Dear Darling,\\nI have always wanted to write y...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>Darling,\\nI want you to know that there's no o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>Dear,\\nMy life is beautiful because of you my ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>Dear,\\nIn life there are certain things that w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>To my forever person,\\nI think we make the per...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   ID                                               Text\n",
       "0   1  Dear Darling,\\nI have always wanted to write y...\n",
       "1   2  Darling,\\nI want you to know that there's no o...\n",
       "2   3  Dear,\\nMy life is beautiful because of you my ...\n",
       "3   4  Dear,\\nIn life there are certain things that w...\n",
       "4   5  To my forever person,\\nI think we make the per..."
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Corpus.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "建立一個大的文本集"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_text = \"\"\n",
    "for text in Corpus[\"Text\"]:\n",
    "    All_text += text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "將字母轉為小寫，減少之後字元向量的維度"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "All_text = All_text.lower()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本集前190字元:\n",
      "dear darling,\n",
      "i have always wanted to write you a love letter, though i don't know how to begin.\n",
      "when i am with you, i am lost of words, my heart yearns for you.\n",
      "you are the love of my life. \n"
     ]
    }
   ],
   "source": [
    "print(f\"文本集前190字元:\\n{All_text[:190]} \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "文本集共16285個字元\n"
     ]
    }
   ],
   "source": [
    "print(f\"文本集共{len(All_text)}個字元\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 準備訓練集\n",
    "把文本集切割成許多片段，並由下一個字元當作標籤"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment = [] # 文本片段\n",
    "next_char = [] # 該片段的下一個字元\n",
    "segment_len = 50\n",
    "last_segment_start_ith = len(All_text)-segment_len # 最後一個片段的\n",
    "for i in range(0,last_segment_start_ith):\n",
    "    segment.append(All_text[i:i+segment_len])\n",
    "    next_char.append(All_text[i+segment_len])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "由於我們共有16285個字元，每50個字元切割一片段，每個切割後只右移1個字元，所以理論上有16285-50 = 16235個片段"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(樣本數)片段數: 16235 標籤數: 16235\n"
     ]
    }
   ],
   "source": [
    "print(\"(樣本數)片段數:\",len(segment),\"標籤數:\",len(next_char))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "第1201筆訓練資料:\n",
      "s,to my forever person,\n",
      "i think we make the perfec\n",
      "\n",
      "第1201筆標籤:\n",
      "t\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "i = np.random.randint(len(segment))\n",
    "print(f\"第{i}筆訓練資料:\\n{segment[i]}\\n\") \n",
    "print(f\"第{i}筆標籤:\\n{next_char[i]}\") "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 字元向量\n",
    "把a,b,c,...,z以及一些標點符號做one-hot encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_char = []\n",
    "for i in range(len(All_text)):\n",
    "    all_char.append(All_text[i])\n",
    "all_unique_char = np.unique(all_char)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "取得所有獨立的字元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "獨立字元有39個\n",
      "['\\n' ' ' '!' \"'\" ',' '-' '.' ';' '?' 'a' 'b' 'c' 'd' 'e' 'f' 'g' 'h' 'i'\n",
      " 'j' 'k' 'l' 'm' 'n' 'o' 'p' 'q' 'r' 's' 't' 'u' 'v' 'w' 'x' 'y' 'z' '–'\n",
      " '—' '’' '…']\n"
     ]
    }
   ],
   "source": [
    "print(f\"獨立字元有{len(all_unique_char)}個\\n{all_unique_char}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn的OneHotEncoder()只能吃2d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_unique_char = np.array(all_unique_char)\n",
    "all_unique_char = all_unique_char.reshape((len(all_unique_char),1)) #將39個字元轉為2d array\n",
    "\n",
    "segment = np.array(segment)\n",
    "segment = segment.reshape((len(segment),1)) #將39個字元轉為2d array\n",
    "\n",
    "next_char = np.array(next_char)\n",
    "next_char = next_char.reshape((len(next_char),1)) #將39個字元轉為2d array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['\\n'],\n",
       "       [' '],\n",
       "       ['!'],\n",
       "       [\"'\"],\n",
       "       [','],\n",
       "       ['-'],\n",
       "       ['.'],\n",
       "       [';'],\n",
       "       ['?'],\n",
       "       ['a'],\n",
       "       ['b'],\n",
       "       ['c'],\n",
       "       ['d'],\n",
       "       ['e'],\n",
       "       ['f'],\n",
       "       ['g'],\n",
       "       ['h'],\n",
       "       ['i'],\n",
       "       ['j'],\n",
       "       ['k'],\n",
       "       ['l'],\n",
       "       ['m'],\n",
       "       ['n'],\n",
       "       ['o'],\n",
       "       ['p'],\n",
       "       ['q'],\n",
       "       ['r'],\n",
       "       ['s'],\n",
       "       ['t'],\n",
       "       ['u'],\n",
       "       ['v'],\n",
       "       ['w'],\n",
       "       ['x'],\n",
       "       ['y'],\n",
       "       ['z'],\n",
       "       ['–'],\n",
       "       ['—'],\n",
       "       ['’'],\n",
       "       ['…']], dtype='<U1')"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_unique_char[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([['l'],\n",
       "       ['o'],\n",
       "       ['v'],\n",
       "       ...,\n",
       "       ['v'],\n",
       "       ['e'],\n",
       "       ['.']], dtype='<U1')"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_char"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "ohe = OneHotEncoder()\n",
    "ohe.fit(all_unique_char)\n",
    "y = ohe.transform(next_char).toarray() # label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "每1個字元(或稱token)現在由1個39維向量表示，所以y變成16235 x 39 維的矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "比較麻煩的是如何將segment變成 16235x50x39 的矩陣"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['u.\\nlove you forever and always.\\n\\nwith lots of love'],\n",
       "      dtype='<U50')"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 我希望1個片段變成 50x39維的東西\n",
    "text = segment[16234]\n",
    "text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = []\n",
    "for i in range(len(segment)):\n",
    "    text = segment[i]\n",
    "    all_char_in_text = []\n",
    "    for j in range(segment_len):\n",
    "        all_char_in_text.append(text[0][j])\n",
    "    all_char_in_text = np.array(all_char_in_text)\n",
    "    all_char_in_text = all_char_in_text.reshape((-1,1))\n",
    "    all_char_in_text = ohe.transform(all_char_in_text).toarray()\n",
    "    #print(all_char_in_text.shape)\n",
    "    X.append(all_char_in_text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = np.array(X)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "趕緊看看上面的魔法成功了沒"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16235, 50, 39)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# X.reshape((len(segment),segment_len,len(all_unique_char)))\n",
    "X.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 建立LSTM模型"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "segment_len = 50 #1個片段有50個字元\n",
    "vocab = 39 #有39個字元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"sequential_7\"\n",
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "lstm_11 (LSTM)               (None, 50, 128)           86016     \n",
      "_________________________________________________________________\n",
      "lstm_12 (LSTM)               (None, 128)               131584    \n",
      "_________________________________________________________________\n",
      "dense_8 (Dense)              (None, 39)                5031      \n",
      "=================================================================\n",
      "Total params: 222,631\n",
      "Trainable params: 222,631\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import LSTM, Dense\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(128,return_sequences= True,input_shape= (segment_len, vocab)))\n",
    "model.add(LSTM(128,input_shape= (segment_len, vocab)))\n",
    "model.add(Dense(vocab, activation= \"softmax\"))\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss= \"categorical_crossentropy\", optimizer= \"adam\", metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 16235 samples\n",
      "Epoch 1/128\n",
      "16235/16235 [==============================] - 24s 1ms/sample - loss: 3.0099 - accuracy: 0.1826\n",
      "Epoch 2/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 2.8739 - accuracy: 0.2075s - loss: 2.8791 - accura\n",
      "Epoch 3/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 2.5156 - accuracy: 0.2917\n",
      "Epoch 4/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 2.2433 - accuracy: 0.3402\n",
      "Epoch 5/128\n",
      "16235/16235 [==============================] - 19s 1ms/sample - loss: 2.1052 - accuracy: 0.3908\n",
      "Epoch 6/128\n",
      "16235/16235 [==============================] - 19s 1ms/sample - loss: 2.0133 - accuracy: 0.4113\n",
      "Epoch 7/128\n",
      "16235/16235 [==============================] - 21s 1ms/sample - loss: 1.9442 - accuracy: 0.4360\n",
      "Epoch 8/128\n",
      "16235/16235 [==============================] - 25s 2ms/sample - loss: 1.8842 - accuracy: 0.4520\n",
      "Epoch 9/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 1.8306 - accuracy: 0.4660\n",
      "Epoch 10/128\n",
      "16235/16235 [==============================] - 23s 1ms/sample - loss: 1.7837 - accuracy: 0.4796\n",
      "Epoch 11/128\n",
      "16235/16235 [==============================] - 21s 1ms/sample - loss: 1.7367 - accuracy: 0.4928\n",
      "Epoch 12/128\n",
      "16235/16235 [==============================] - 22s 1ms/sample - loss: 1.6967 - accuracy: 0.5059\n",
      "Epoch 13/128\n",
      "16235/16235 [==============================] - 22s 1ms/sample - loss: 1.6546 - accuracy: 0.5170\n",
      "Epoch 14/128\n",
      "16235/16235 [==============================] - 23s 1ms/sample - loss: 1.6170 - accuracy: 0.5261\n",
      "Epoch 15/128\n",
      "16235/16235 [==============================] - 23s 1ms/sample - loss: 1.5783 - accuracy: 0.5363\n",
      "Epoch 16/128\n",
      "16235/16235 [==============================] - 22s 1ms/sample - loss: 1.5398 - accuracy: 0.5472\n",
      "Epoch 17/128\n",
      "16235/16235 [==============================] - 21s 1ms/sample - loss: 1.4996 - accuracy: 0.5567\n",
      "Epoch 18/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 1.4646 - accuracy: 0.5687\n",
      "Epoch 19/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 1.4285 - accuracy: 0.5774\n",
      "Epoch 20/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 1.3919 - accuracy: 0.5895\n",
      "Epoch 21/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 1.3535 - accuracy: 0.5994\n",
      "Epoch 22/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 1.3138 - accuracy: 0.6105\n",
      "Epoch 23/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 1.2828 - accuracy: 0.6188\n",
      "Epoch 24/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 1.2441 - accuracy: 0.6322\n",
      "Epoch 25/128\n",
      "16235/16235 [==============================] - 21s 1ms/sample - loss: 1.2061 - accuracy: 0.6435\n",
      "Epoch 26/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 1.1673 - accuracy: 0.6575\n",
      "Epoch 27/128\n",
      "16235/16235 [==============================] - 21s 1ms/sample - loss: 1.1307 - accuracy: 0.6661\n",
      "Epoch 28/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 1.0914 - accuracy: 0.6780\n",
      "Epoch 29/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 1.0518 - accuracy: 0.6936\n",
      "Epoch 30/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 1.0150 - accuracy: 0.7058\n",
      "Epoch 31/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 0.9728 - accuracy: 0.7156\n",
      "Epoch 32/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 0.9369 - accuracy: 0.7265s - loss: 0.9346 \n",
      "Epoch 33/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 0.8939 - accuracy: 0.7433\n",
      "Epoch 34/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 0.8608 - accuracy: 0.7494\n",
      "Epoch 35/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 0.8171 - accuracy: 0.7648\n",
      "Epoch 36/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 0.7792 - accuracy: 0.7774\n",
      "Epoch 37/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 0.7429 - accuracy: 0.7910\n",
      "Epoch 38/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 0.7048 - accuracy: 0.8040\n",
      "Epoch 39/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 0.6689 - accuracy: 0.8132\n",
      "Epoch 40/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 0.6300 - accuracy: 0.8246\n",
      "Epoch 41/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 0.5932 - accuracy: 0.8366\n",
      "Epoch 42/128\n",
      "16235/16235 [==============================] - 21s 1ms/sample - loss: 0.5623 - accuracy: 0.8468\n",
      "Epoch 43/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 0.5281 - accuracy: 0.8611\n",
      "Epoch 44/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 0.4973 - accuracy: 0.8700\n",
      "Epoch 45/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 0.4619 - accuracy: 0.8824\n",
      "Epoch 46/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 0.4358 - accuracy: 0.8892\n",
      "Epoch 47/128\n",
      "16235/16235 [==============================] - 21s 1ms/sample - loss: 0.4015 - accuracy: 0.9024\n",
      "Epoch 48/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 0.3689 - accuracy: 0.9131\n",
      "Epoch 49/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 0.3448 - accuracy: 0.9217\n",
      "Epoch 50/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 0.3184 - accuracy: 0.9306\n",
      "Epoch 51/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 0.2930 - accuracy: 0.9390\n",
      "Epoch 52/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 0.2708 - accuracy: 0.9458\n",
      "Epoch 53/128\n",
      "16235/16235 [==============================] - 21s 1ms/sample - loss: 0.2440 - accuracy: 0.9538\n",
      "Epoch 54/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 0.2322 - accuracy: 0.9552\n",
      "Epoch 55/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 0.2048 - accuracy: 0.9646\n",
      "Epoch 56/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 0.1868 - accuracy: 0.9704\n",
      "Epoch 57/128\n",
      "16235/16235 [==============================] - 20s 1ms/sample - loss: 0.1789 - accuracy: 0.9718\n",
      "Epoch 58/128\n",
      "16235/16235 [==============================] - 23s 1ms/sample - loss: 0.1645 - accuracy: 0.9756\n",
      "Epoch 59/128\n",
      "16235/16235 [==============================] - 21s 1ms/sample - loss: 0.1466 - accuracy: 0.9797\n",
      "Epoch 60/128\n",
      "16235/16235 [==============================] - 21s 1ms/sample - loss: 0.1275 - accuracy: 0.9849\n",
      "Epoch 61/128\n",
      "16235/16235 [==============================] - 22s 1ms/sample - loss: 0.1082 - accuracy: 0.9891\n",
      "Epoch 62/128\n",
      "16235/16235 [==============================] - 22s 1ms/sample - loss: 0.0954 - accuracy: 0.9924\n",
      "Epoch 63/128\n",
      "16235/16235 [==============================] - 24s 1ms/sample - loss: 0.0967 - accuracy: 0.9912\n",
      "Epoch 64/128\n",
      "16235/16235 [==============================] - 25s 2ms/sample - loss: 0.1074 - accuracy: 0.9872\n",
      "Epoch 65/128\n",
      "16235/16235 [==============================] - 25s 2ms/sample - loss: 0.1102 - accuracy: 0.9863\n",
      "Epoch 66/128\n",
      "16235/16235 [==============================] - 23s 1ms/sample - loss: 0.0938 - accuracy: 0.9897\n",
      "Epoch 67/128\n",
      "16235/16235 [==============================] - 23s 1ms/sample - loss: 0.0737 - accuracy: 0.9951\n",
      "Epoch 68/128\n",
      "16235/16235 [==============================] - 24s 1ms/sample - loss: 0.0742 - accuracy: 0.9935\n",
      "Epoch 69/128\n",
      "16235/16235 [==============================] - 26s 2ms/sample - loss: 0.0666 - accuracy: 0.9948\n",
      "Epoch 70/128\n",
      "16235/16235 [==============================] - 23s 1ms/sample - loss: 0.0527 - accuracy: 0.9976\n",
      "Epoch 71/128\n",
      "16235/16235 [==============================] - 25s 2ms/sample - loss: 0.0407 - accuracy: 0.9986\n",
      "Epoch 72/128\n",
      "16235/16235 [==============================] - 23s 1ms/sample - loss: 0.0322 - accuracy: 0.9994\n",
      "Epoch 73/128\n",
      "16235/16235 [==============================] - 25s 2ms/sample - loss: 0.0246 - accuracy: 0.9997\n",
      "Epoch 74/128\n",
      "16235/16235 [==============================] - 21s 1ms/sample - loss: 0.0209 - accuracy: 0.9996\n",
      "Epoch 75/128\n",
      "16235/16235 [==============================] - 21s 1ms/sample - loss: 0.0189 - accuracy: 0.9998\n",
      "Epoch 76/128\n",
      "16235/16235 [==============================] - 21s 1ms/sample - loss: 0.0167 - accuracy: 0.9998\n",
      "Epoch 77/128\n",
      "16235/16235 [==============================] - 21s 1ms/sample - loss: 0.0150 - accuracy: 0.9999\n",
      "Epoch 78/128\n",
      "16235/16235 [==============================] - 22s 1ms/sample - loss: 0.0141 - accuracy: 0.9998\n",
      "Epoch 79/128\n",
      "16235/16235 [==============================] - 22s 1ms/sample - loss: 0.0126 - accuracy: 0.9998\n",
      "Epoch 80/128\n",
      "16235/16235 [==============================] - 21s 1ms/sample - loss: 0.0122 - accuracy: 0.9999\n",
      "Epoch 81/128\n",
      "16235/16235 [==============================] - 21s 1ms/sample - loss: 0.0111 - accuracy: 0.9999\n",
      "Epoch 82/128\n",
      "16235/16235 [==============================] - 22s 1ms/sample - loss: 0.4380 - accuracy: 0.8793\n",
      "Epoch 83/128\n",
      "16235/16235 [==============================] - 22s 1ms/sample - loss: 0.5138 - accuracy: 0.8341\n",
      "Epoch 84/128\n",
      "16235/16235 [==============================] - 22s 1ms/sample - loss: 0.1847 - accuracy: 0.9479\n",
      "Epoch 85/128\n",
      "16235/16235 [==============================] - 23s 1ms/sample - loss: 0.0790 - accuracy: 0.9894\n",
      "Epoch 86/128\n",
      "16235/16235 [==============================] - 24s 1ms/sample - loss: 0.0424 - accuracy: 0.9987\n",
      "Epoch 87/128\n",
      "16235/16235 [==============================] - 23s 1ms/sample - loss: 0.0263 - accuracy: 0.9994\n",
      "Epoch 88/128\n",
      "16235/16235 [==============================] - 24s 1ms/sample - loss: 0.0204 - accuracy: 0.9998\n",
      "Epoch 89/128\n",
      "16235/16235 [==============================] - 23s 1ms/sample - loss: 0.0170 - accuracy: 0.9998\n",
      "Epoch 90/128\n",
      "16235/16235 [==============================] - 23s 1ms/sample - loss: 0.0150 - accuracy: 0.9999\n",
      "Epoch 91/128\n",
      "16235/16235 [==============================] - 24s 1ms/sample - loss: 0.0134 - accuracy: 0.9998\n",
      "Epoch 92/128\n",
      "16235/16235 [==============================] - 28s 2ms/sample - loss: 0.0118 - accuracy: 0.9999\n",
      "Epoch 93/128\n",
      "16235/16235 [==============================] - 26s 2ms/sample - loss: 0.0108 - accuracy: 0.9999\n",
      "Epoch 94/128\n",
      "16235/16235 [==============================] - 26s 2ms/sample - loss: 0.0100 - accuracy: 0.9998s - loss: 0.0099 - accuracy: 0. - ETA\n",
      "Epoch 95/128\n",
      "16235/16235 [==============================] - 25s 2ms/sample - loss: 0.0093 - accuracy: 0.9998\n",
      "Epoch 96/128\n",
      "16235/16235 [==============================] - 26s 2ms/sample - loss: 0.0085 - accuracy: 0.9999\n",
      "Epoch 97/128\n",
      "16235/16235 [==============================] - 27s 2ms/sample - loss: 0.0080 - accuracy: 0.9998\n",
      "Epoch 98/128\n",
      "16235/16235 [==============================] - 29s 2ms/sample - loss: 0.0075 - accuracy: 0.9998\n",
      "Epoch 99/128\n",
      "16235/16235 [==============================] - 26s 2ms/sample - loss: 0.0070 - accuracy: 0.9998\n",
      "Epoch 100/128\n",
      "16235/16235 [==============================] - 26s 2ms/sample - loss: 0.0064 - accuracy: 0.9999\n",
      "Epoch 101/128\n",
      "16235/16235 [==============================] - 26s 2ms/sample - loss: 0.0059 - accuracy: 0.9999\n",
      "Epoch 102/128\n",
      "16235/16235 [==============================] - 21s 1ms/sample - loss: 0.0057 - accuracy: 0.9998\n",
      "Epoch 103/128\n",
      "16235/16235 [==============================] - 22s 1ms/sample - loss: 0.0054 - accuracy: 0.9998\n",
      "Epoch 104/128\n",
      "16235/16235 [==============================] - 24s 1ms/sample - loss: 0.0052 - accuracy: 0.9998\n",
      "Epoch 105/128\n",
      "16235/16235 [==============================] - 23s 1ms/sample - loss: 0.0047 - accuracy: 0.9998\n",
      "Epoch 106/128\n",
      "16235/16235 [==============================] - 23s 1ms/sample - loss: 0.0090 - accuracy: 0.9990\n",
      "Epoch 107/128\n",
      "16235/16235 [==============================] - 23s 1ms/sample - loss: 0.7631 - accuracy: 0.7765\n",
      "Epoch 108/128\n",
      "16235/16235 [==============================] - 22s 1ms/sample - loss: 0.2607 - accuracy: 0.9139\n",
      "Epoch 109/128\n",
      "16235/16235 [==============================] - 21s 1ms/sample - loss: 0.0999 - accuracy: 0.9784\n",
      "Epoch 110/128\n",
      "16235/16235 [==============================] - 21s 1ms/sample - loss: 0.0451 - accuracy: 0.9949\n",
      "Epoch 111/128\n",
      "16235/16235 [==============================] - 21s 1ms/sample - loss: 0.0259 - accuracy: 0.9987\n",
      "Epoch 112/128\n",
      "16235/16235 [==============================] - 21s 1ms/sample - loss: 0.0163 - accuracy: 0.9997\n",
      "Epoch 113/128\n",
      "16235/16235 [==============================] - 21s 1ms/sample - loss: 0.0126 - accuracy: 0.9998\n",
      "Epoch 114/128\n",
      "16235/16235 [==============================] - 23s 1ms/sample - loss: 0.0108 - accuracy: 0.9998\n",
      "Epoch 115/128\n",
      "16235/16235 [==============================] - 23s 1ms/sample - loss: 0.0095 - accuracy: 0.9999\n",
      "Epoch 116/128\n",
      "16235/16235 [==============================] - 22s 1ms/sample - loss: 0.0085 - accuracy: 0.9998\n",
      "Epoch 117/128\n",
      "16235/16235 [==============================] - 23s 1ms/sample - loss: 0.0078 - accuracy: 0.9998\n",
      "Epoch 118/128\n",
      "16235/16235 [==============================] - 25s 2ms/sample - loss: 0.0071 - accuracy: 0.9998\n",
      "Epoch 119/128\n",
      "16235/16235 [==============================] - 23s 1ms/sample - loss: 0.0066 - accuracy: 0.9998\n",
      "Epoch 120/128\n",
      "16235/16235 [==============================] - 25s 2ms/sample - loss: 0.0061 - accuracy: 0.9998\n",
      "Epoch 121/128\n",
      "16235/16235 [==============================] - 25s 2ms/sample - loss: 0.0057 - accuracy: 0.9998\n",
      "Epoch 122/128\n",
      "16235/16235 [==============================] - 25s 2ms/sample - loss: 0.0053 - accuracy: 0.9999\n",
      "Epoch 123/128\n",
      "16235/16235 [==============================] - 25s 2ms/sample - loss: 0.0049 - accuracy: 0.9998\n",
      "Epoch 124/128\n",
      "16235/16235 [==============================] - 24s 1ms/sample - loss: 0.0046 - accuracy: 0.9998\n",
      "Epoch 125/128\n",
      "16235/16235 [==============================] - 24s 1ms/sample - loss: 0.0044 - accuracy: 0.9998\n",
      "Epoch 126/128\n",
      "16235/16235 [==============================] - 25s 2ms/sample - loss: 0.0041 - accuracy: 0.9998\n",
      "Epoch 127/128\n",
      "16235/16235 [==============================] - 24s 2ms/sample - loss: 0.0039 - accuracy: 0.9998\n",
      "Epoch 128/128\n",
      "16235/16235 [==============================] - 24s 1ms/sample - loss: 0.0040 - accuracy: 0.9998\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<tensorflow.python.keras.callbacks.History at 0x21125e43cc8>"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(X, y, batch_size= 128, epochs= 128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [],
   "source": [
    "# 訓練完先保存下來! 這很重要! \n",
    "#model.save(\"LSTM_love_letter_generator.h5\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 預測下個字元"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['dear darling,\\ni have always wanted to write you a '],\n",
       "      dtype='<U50')"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "segment[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test = X[0].reshape((1,50,39))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       ...,\n",
       "       [0., 1., 0., ..., 0., 0., 0.],\n",
       "       [0., 0., 0., ..., 0., 0., 0.],\n",
       "       [0., 1., 0., ..., 0., 0., 0.]])"
      ]
     },
     "execution_count": 113,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[[0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        ...,\n",
       "        [0., 1., 0., ..., 0., 0., 0.],\n",
       "        [0., 0., 0., ..., 0., 0., 0.],\n",
       "        [0., 1., 0., ..., 0., 0., 0.]]])"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = model.predict(X,verbose=0)[0] #預測第1筆樣本下一個字元"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "這些數字是機率，all_unique_char中的字元所對應的機率，機率高的字元會被挑選做預測的下一個字"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.9070106e-11, 1.3052043e-09, 6.8992222e-08, 4.6052597e-09,\n",
       "       2.8658454e-07, 2.5745487e-07, 3.5795324e-06, 1.5135632e-10,\n",
       "       1.2997581e-10, 1.2676900e-05, 6.9028982e-07, 2.7030837e-06,\n",
       "       9.9199743e-04, 5.5679874e-09, 1.3244100e-05, 2.2519626e-09,\n",
       "       1.1515544e-05, 3.9250776e-09, 7.3596368e-08, 9.0198391e-06,\n",
       "       9.9755114e-01, 1.3567262e-03, 5.3423628e-07, 1.2348648e-11,\n",
       "       3.6994668e-05, 3.3877807e-09, 6.3369447e-07, 2.0262206e-07,\n",
       "       2.2632770e-07, 5.4214747e-11, 1.4280286e-07, 6.0345906e-06,\n",
       "       1.3655009e-06, 3.7610895e-10, 2.5610980e-12, 1.3911892e-08,\n",
       "       2.1594023e-08, 5.6834427e-08, 1.6078159e-09], dtype=float32)"
      ]
     },
     "execution_count": 116,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## greedy selection + multinormial distribution\n",
    "將機率縮放(開根號)，以至於常態分配比較符合我們的期望"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = pred**(0.5)\n",
    "pred = pred / np.sum(pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([9.04740227e-06, 3.28391470e-05, 2.38755107e-04, 6.16850157e-05,\n",
       "       4.86607722e-04, 4.61214775e-04, 1.71975186e-03, 1.11828604e-05,\n",
       "       1.03629618e-05, 3.23637738e-03, 7.55211106e-04, 1.49445341e-03,\n",
       "       2.86291149e-02, 6.78268625e-05, 3.30798747e-03, 4.31353365e-05,\n",
       "       3.08457157e-03, 5.69477743e-05, 2.46593030e-04, 2.72993301e-03,\n",
       "       9.07862782e-01, 3.34810205e-02, 6.64384221e-04, 3.19420155e-06,\n",
       "       5.52868936e-03, 5.29066492e-05, 7.23590027e-04, 4.09162662e-04,\n",
       "       4.32435627e-04, 6.69285373e-06, 3.43495514e-04, 2.23293738e-03,\n",
       "       1.06218120e-03, 1.76282592e-05, 1.45467413e-06, 1.07212574e-04,\n",
       "       1.33573223e-04, 2.16699729e-04, 3.64477564e-05], dtype=float32)"
      ]
     },
     "execution_count": 118,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "基本上，會挑選機率最大的字元，但這樣會減少隨機性。\n",
    "因此我們會將機率擬合成多元常態分配，從該分配中抽取字元。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "20\n"
     ]
    }
   ],
   "source": [
    "next_onehot = np.random.multinomial(1,pred,1)\n",
    "next_index = np.argmax(next_onehot)\n",
    "print(next_index)\n",
    "next_char_pred = all_unique_char[next_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "這是第一個片段: ['dear darling,\\ni have always wanted to write you a ']\n",
      "預測下一個字元為: ['l']\n",
      "實際下一個字元為: ['l']\n"
     ]
    }
   ],
   "source": [
    "print(\"這是第一個片段:\", segment[0])\n",
    "print(\"預測下一個字元為:\",next_char_pred)\n",
    "print(\"實際下一個字元為:\",next_char[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "寫成一個function吧! 接下來可是要狂用他呢!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_2d_input(text):\n",
    "    all_char_in_text = []\n",
    "    for j in range(segment_len):\n",
    "        all_char_in_text.append(text[0][j])\n",
    "    all_char_in_text = np.array(all_char_in_text)\n",
    "    all_char_in_text = all_char_in_text.reshape((-1,1))\n",
    "    all_char_in_text = ohe.transform(all_char_in_text).toarray()\n",
    "    return all_char_in_text\n",
    "\n",
    "def generate_next_char(text_input):\n",
    "    \"\"\"\n",
    "    text_input (str) : 50 char\n",
    "    \"\"\"\n",
    "    x_input = get_2d_input(np.array([text_input]))\n",
    "    x_input = x_input.reshape((1,50,39)) # 1個片段，50個字元，39維字元向量\n",
    "    #print(x_input)\n",
    "    pred = model.predict(x_input,verbose=0)[0] #預測第1筆樣本下一個字元\n",
    "    pred = pred**(0.5)\n",
    "    pred = pred / (np.sum(pred)+ 0.00001)\n",
    "    #print(pred)\n",
    "    next_onehot = np.random.multinomial(1,pred,1)\n",
    "    next_index = np.argmax(next_onehot)\n",
    "    next_char_pred = all_unique_char[next_index]\n",
    "    return next_char_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "下一個字元:  ['s']\n"
     ]
    }
   ],
   "source": [
    "text_input = 't like this ,before in my life. my love for you ha'\n",
    "a = generate_next_char(text_input)\n",
    "print(\"下一個字元: \",a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 寫情書囉!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generate_love_letter(text_input,letter_length):\n",
    "    \"\"\"\n",
    "    text_input (str) : 50 char\n",
    "    letter_length (int > 50): max number of chars in this letter(original 50 chars are included)\n",
    "    output(str):\n",
    "    \"\"\"\n",
    "    #print(\"初始片段\\n\",text_input)\n",
    "    all_text_output = text_input\n",
    "    while(len(all_text_output) < letter_length):\n",
    "        next_char_pred = generate_next_char(text_input)\n",
    "        text_input = text_input[1:] + next_char_pred[0]\n",
    "        \n",
    "        all_text_output = all_text_output + next_char_pred[0]\n",
    "    print(\"生成文章\\n\",all_text_output)\n",
    "    return all_text_output"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "生成文章\n",
      " dear darling,i have always wanted to write you a lode being with you. thriss you thours,\n",
      "you have ogher hopet. a l ips. white upperting my diming. runtiing that the was neade eace we prepies to beca l\n"
     ]
    }
   ],
   "source": [
    "begining_text = \"Dear Darling,I have always wanted to write you a love letter, though I don't know how to begin.\"\n",
    "begining_text = begining_text.lower()\n",
    "my_love_letter = generate_love_letter(begining_text[:50],200)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 英文不好？有請谷哥翻譯"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Translated(src=en, dest=en, text=dear darling,i have always wanted to write you a lode being with you. thriss you thours,\n",
      "you have ogher hopet. a l ips. white upperting my diming. runtiing that the was neade eace we prepies to beca l, pronunciation=dear darling,i have always wanted to write you a lode being with you. thriss you thours,\n",
      "you have ogher hopet. a l ips. white upperting my diming. runtiing that the was neade eace we prepies to beca l, extra_data=\"{'translat...\")\n"
     ]
    }
   ],
   "source": [
    "import googletrans\n",
    "# Initial\n",
    "translator = googletrans.Translator()\n",
    "\n",
    "# Basic Translate\n",
    "results = translator.translate(my_love_letter)\n",
    "print(results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "#googletrans.LANGCODES"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "繁體中文:\n",
      " 親愛的親愛的，我一直想給你寫信給你。幾小時後，\n",
      "你有希望。一點點白色使我昏暗。冒充我們準備過的那不整潔的面孔\n"
     ]
    }
   ],
   "source": [
    "print('繁體中文:\\n', translator.translate(my_love_letter, dest='zh-tw').text)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 自由創作區 7/28以後直接執行以下內容"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.models import load_model\n",
    "model = load_model('LSTM_love_letter_generator.h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Final_present():\n",
    "    begining_text = input(\"請輸入英文句子(至少50個字，不能有數字):\\n\")\n",
    "    begining_text = begining_text.lower()\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    my_love_letter = generate_love_letter(begining_text[:50],1000)\n",
    "    print(\"-------------------------------------------------------\")\n",
    "    print('繁體中文:\\n', translator.translate(my_love_letter, dest='zh-tw').text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "請輸入英文句子(至少50個字，不能有數字):\n",
      "I the short-time tenderness, as long as you life-long companion.\n",
      "-------------------------------------------------------\n",
      "生成文章\n",
      " i the short-time tenderness, as long as you life-ly and isaver af asfout in me coonn thin'i dow ore love comy bate want to tho love.\n",
      "you ralts every and kquis mat in s!opachito.\n",
      "you ma tbo me thisk for ne loving you have verywiretde who connedsin toway sinders.\n",
      "we bofny seepest to \n",
      "mebbingy i am shawirst’pes agains. muntit ig virm beath for.\n",
      "you are the love of rucian\n",
      "i, a, wontet mo,\n",
      "i hasplestver love forever no one a this momentin qould brick wels i i good uxtnce that thr ow dred ted son i nowe lajuga to me.\n",
      "i love you dy wlod that eving unde, i rone allayd pprsep be.\n",
      "you hame you hand niver and camile ab babte wiffe.\n",
      "you make you blize forsnede that is om wlounl mefeeretheal, then you have glopfest to me.\n",
      "love you for very comlt on wyo me agriss my dad. i mopprest heart nas so — and known to jist nit!\n",
      "i love unchac told remantin fore, i feew you mese my heart, my ghary dros?demhene, the litet you moke ap suling loving and ways the live to sempll?s youp with mern.\n",
      "worling love.\n",
      "you \n",
      "-------------------------------------------------------\n",
      "繁體中文:\n",
      " 我是短暫的溫柔，只要您在我的生活中充滿活力，並且愛我就喜歡我。\n",
      "您將在s！opachito中召集所有人和kquis墊子。\n",
      "您可能會因為我不愛您而向我求婚，因為您有一個非常笨拙的人，他們總是沉迷於犯罪。\n",
      "我們波菲尼\n",
      "輕描淡寫的我是肖爾斯特的反抗。 muntit ig virm beath為。\n",
      "你是rucian的愛\n",
      "我，一個，不會，\n",
      "我擁有永遠的愛，直到現在，沒有人會愛上我，我很樂意給兒子拉尤加。\n",
      "我愛你，今天晚安，我羅納德·阿萊德·普普塞普。\n",
      "你有你的手，尼弗和脆弱的嬰兒。\n",
      "你讓你在整個職業生涯中都蒙混過關，那麼你對我就感到最痛心。\n",
      "愛你，因為我對懷俄明州（Wyo Me）和我的父親非常滿意。我如此猛擊心臟納斯（Jist nit）！\n",
      "我愛unchac告訴remantin脫穎而出，我想告訴你我的心，我的丈夫，你喜歡的小愛人，以及如何與人分享生活的方式。\n",
      "痛苦的愛。\n",
      "您\n"
     ]
    }
   ],
   "source": [
    "Final_present()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
